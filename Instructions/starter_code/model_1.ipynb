{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\etorrente\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\etorrente\\anaconda3\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\etorrente\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\etorrente\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\etorrente\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\etorrente\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\etorrente\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X = df.drop(['koi_disposition'], axis=1)\n",
    "\n",
    "y = df['koi_disposition'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>1.846000e-04</td>\n",
       "      <td>-1.846000e-04</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>-0.015700</td>\n",
       "      <td>...</td>\n",
       "      <td>-152</td>\n",
       "      <td>4.296</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>1.160000e-07</td>\n",
       "      <td>-1.160000e-07</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>-166</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>1.780000e-05</td>\n",
       "      <td>-1.780000e-05</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>-0.007690</td>\n",
       "      <td>...</td>\n",
       "      <td>-220</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>2.430000e-06</td>\n",
       "      <td>-2.430000e-06</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>-0.002850</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>4.447</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>6.360000e-05</td>\n",
       "      <td>-6.360000e-05</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>-225</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0                 0              0              0              0   54.418383   \n",
       "1                 0              1              0              0   19.899140   \n",
       "2                 0              1              0              0    1.736952   \n",
       "3                 0              0              0              0    2.525592   \n",
       "4                 0              0              0              0    4.134435   \n",
       "...             ...            ...            ...            ...         ...   \n",
       "6986              0              0              0              1    8.589871   \n",
       "6987              0              1              1              0    0.527699   \n",
       "6988              0              0              0              0    1.739849   \n",
       "6989              0              0              1              0    0.681402   \n",
       "6990              0              0              1              1    4.856035   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "0        2.479000e-04    -2.479000e-04   162.513840          0.003520   \n",
       "1        1.490000e-05    -1.490000e-05   175.850252          0.000581   \n",
       "2        2.630000e-07    -2.630000e-07   170.307565          0.000115   \n",
       "3        3.760000e-06    -3.760000e-06   171.595550          0.001130   \n",
       "4        1.050000e-05    -1.050000e-05   172.979370          0.001900   \n",
       "...               ...              ...          ...               ...   \n",
       "6986     1.846000e-04    -1.846000e-04   132.016100          0.015700   \n",
       "6987     1.160000e-07    -1.160000e-07   131.705093          0.000170   \n",
       "6988     1.780000e-05    -1.780000e-05   133.001270          0.007690   \n",
       "6989     2.430000e-06    -2.430000e-06   132.181750          0.002850   \n",
       "6990     6.360000e-05    -6.360000e-05   135.993300          0.010800   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0            -0.003520  ...             -81      4.467           0.064   \n",
       "1            -0.000581  ...            -176      4.544           0.044   \n",
       "2            -0.000115  ...            -174      4.564           0.053   \n",
       "3            -0.001130  ...            -211      4.438           0.070   \n",
       "4            -0.001900  ...            -232      4.486           0.054   \n",
       "...                ...  ...             ...        ...             ...   \n",
       "6986         -0.015700  ...            -152      4.296           0.231   \n",
       "6987         -0.000170  ...            -166      4.529           0.035   \n",
       "6988         -0.007690  ...            -220      4.444           0.056   \n",
       "6989         -0.002850  ...            -236      4.447           0.056   \n",
       "6990         -0.010800  ...            -225      4.385           0.054   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0             -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1             -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2             -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3             -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4             -0.229     0.972          0.315         -0.105  296.28613   \n",
       "...              ...       ...            ...            ...        ...   \n",
       "6986          -0.189     1.088          0.313         -0.228  298.74921   \n",
       "6987          -0.196     0.903          0.237         -0.079  297.18875   \n",
       "6988          -0.224     1.031          0.341         -0.114  286.50937   \n",
       "6989          -0.224     1.041          0.341         -0.114  294.16489   \n",
       "6990          -0.216     1.193          0.410         -0.137  297.00977   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "0     48.141651      15.347  \n",
       "1     48.134129      15.436  \n",
       "2     48.285210      15.597  \n",
       "3     48.226200      15.509  \n",
       "4     48.224670      15.714  \n",
       "...         ...         ...  \n",
       "6986  46.973351      14.478  \n",
       "6987  47.093819      14.082  \n",
       "6988  47.163219      14.757  \n",
       "6989  47.176281      15.385  \n",
       "6990  47.121021      14.826  \n",
       "\n",
       "[6991 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['CONFIRMED'],\n",
       "       ['FALSE POSITIVE'],\n",
       "       ['FALSE POSITIVE'],\n",
       "       ...,\n",
       "       ['CANDIDATE'],\n",
       "       ['FALSE POSITIVE'],\n",
       "       ['FALSE POSITIVE']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('koi_disposition', axis=1)\n",
    "y = df['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train test and split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768901</td>\n",
       "      <td>7.380000e-05</td>\n",
       "      <td>-7.380000e-05</td>\n",
       "      <td>133.077240</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>...</td>\n",
       "      <td>-171</td>\n",
       "      <td>4.327</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.310</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>39.351681</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733726</td>\n",
       "      <td>6.060000e-06</td>\n",
       "      <td>-6.060000e-06</td>\n",
       "      <td>132.020050</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>...</td>\n",
       "      <td>-175</td>\n",
       "      <td>4.578</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>42.463860</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652707</td>\n",
       "      <td>6.540000e-05</td>\n",
       "      <td>-6.540000e-05</td>\n",
       "      <td>134.460380</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>-0.006190</td>\n",
       "      <td>...</td>\n",
       "      <td>-189</td>\n",
       "      <td>4.481</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>38.983540</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.953547</td>\n",
       "      <td>1.910000e-05</td>\n",
       "      <td>-1.910000e-05</td>\n",
       "      <td>174.662240</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>4.536</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.959319</td>\n",
       "      <td>5.150000e-07</td>\n",
       "      <td>-5.150000e-07</td>\n",
       "      <td>172.258529</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>-77</td>\n",
       "      <td>4.359</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>48.727589</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "6122              0              0              0              0    6.768901   \n",
       "6370              0              1              0              1    0.733726   \n",
       "2879              1              0              0              0    7.652707   \n",
       "107               0              0              0              0    7.953547   \n",
       "29                0              0              0              0    4.959319   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "6122     7.380000e-05    -7.380000e-05   133.077240          0.008440   \n",
       "6370     6.060000e-06    -6.060000e-06   132.020050          0.007950   \n",
       "2879     6.540000e-05    -6.540000e-05   134.460380          0.006190   \n",
       "107      1.910000e-05    -1.910000e-05   174.662240          0.001820   \n",
       "29       5.150000e-07    -5.150000e-07   172.258529          0.000083   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "6122         -0.008440  ...            -171      4.327           0.153   \n",
       "6370         -0.007950  ...            -175      4.578           0.033   \n",
       "2879         -0.006190  ...            -189      4.481           0.050   \n",
       "107          -0.001820  ...             -85      4.536           0.056   \n",
       "29           -0.000083  ...             -77      4.359           0.110   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "6122          -0.187     1.125          0.310         -0.207  294.40472   \n",
       "6370          -0.187     0.797          0.211         -0.056  284.50391   \n",
       "2879          -0.200     0.963          0.290         -0.097  295.50211   \n",
       "107           -0.016     0.779          0.023         -0.049  291.15878   \n",
       "29            -0.110     1.082          0.173         -0.130  292.16705   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "6122  39.351681      14.725  \n",
       "6370  42.463860      15.770  \n",
       "2879  38.983540      13.099  \n",
       "107   40.750271      15.660  \n",
       "29    48.727589      15.263  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#fit the training_data into the scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8899485027655922\n",
      "Testing Data Score: 0.8850114416475973\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {logistic_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "logistic_model_1 = LogisticRegression(solver='newton-cg', multi_class='auto')\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(0, 4, 10),\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "grid_logistic = GridSearchCV(logistic_model_1, param_grid, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(solver='newton-cg'),\n",
       "             param_grid={'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                         'penalty': ['l2']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logistic.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3593.813663804626, 'penalty': 'l2'}\n",
      "0.8897556014816\n"
     ]
    }
   ],
   "source": [
    "print(grid_logistic.best_params_)\n",
    "print(grid_logistic.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49036810986076673"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logistic.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4685354691075515"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logistic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.80      0.72      0.76       411\n",
      "     CONFIRMED       0.78      0.84      0.81       484\n",
      "FALSE POSITIVE       0.98      0.99      0.99       853\n",
      "\n",
      "      accuracy                           0.89      1748\n",
      "     macro avg       0.86      0.85      0.85      1748\n",
      "  weighted avg       0.88      0.89      0.88      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make predictions\n",
    "\n",
    "predict = grid_logistic.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticRegression.sav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'LogisticRegression.sav'\n",
    "joblib.dump(logistic_model_1, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8922372687392714\n",
      "Testing Data Score: 0.8884439359267735\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {svm_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {svm_model.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypertune parameters using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid_svm = GridSearchCV(svm_model, param_grid, verbose=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.900 total time=   0.3s\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.888 total time=   0.3s\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.898 total time=   0.3s\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.878 total time=   0.3s\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.882 total time=   0.4s\n",
      "[CV 1/5] END .................C=1, gamma=0.0005;, score=0.900 total time=   0.3s\n",
      "[CV 2/5] END .................C=1, gamma=0.0005;, score=0.888 total time=   0.3s\n",
      "[CV 3/5] END .................C=1, gamma=0.0005;, score=0.898 total time=   0.3s\n",
      "[CV 4/5] END .................C=1, gamma=0.0005;, score=0.878 total time=   0.3s\n",
      "[CV 5/5] END .................C=1, gamma=0.0005;, score=0.882 total time=   0.4s\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.900 total time=   0.3s\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.888 total time=   0.3s\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.898 total time=   0.3s\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.878 total time=   0.3s\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.882 total time=   0.4s\n",
      "[CV 1/5] END ..................C=1, gamma=0.005;, score=0.900 total time=   0.3s\n",
      "[CV 2/5] END ..................C=1, gamma=0.005;, score=0.888 total time=   0.3s\n",
      "[CV 3/5] END ..................C=1, gamma=0.005;, score=0.898 total time=   0.3s\n",
      "[CV 4/5] END ..................C=1, gamma=0.005;, score=0.878 total time=   0.3s\n",
      "[CV 5/5] END ..................C=1, gamma=0.005;, score=0.882 total time=   0.4s\n",
      "[CV 1/5] END .................C=5, gamma=0.0001;, score=0.900 total time=   0.9s\n",
      "[CV 2/5] END .................C=5, gamma=0.0001;, score=0.889 total time=   1.0s\n",
      "[CV 3/5] END .................C=5, gamma=0.0001;, score=0.899 total time=   0.6s\n",
      "[CV 4/5] END .................C=5, gamma=0.0001;, score=0.880 total time=   0.6s\n",
      "[CV 5/5] END .................C=5, gamma=0.0001;, score=0.881 total time=   0.9s\n",
      "[CV 1/5] END .................C=5, gamma=0.0005;, score=0.900 total time=   0.9s\n",
      "[CV 2/5] END .................C=5, gamma=0.0005;, score=0.889 total time=   1.0s\n",
      "[CV 3/5] END .................C=5, gamma=0.0005;, score=0.899 total time=   0.6s\n",
      "[CV 4/5] END .................C=5, gamma=0.0005;, score=0.880 total time=   0.6s\n",
      "[CV 5/5] END .................C=5, gamma=0.0005;, score=0.881 total time=   0.9s\n",
      "[CV 1/5] END ..................C=5, gamma=0.001;, score=0.900 total time=   0.9s\n",
      "[CV 2/5] END ..................C=5, gamma=0.001;, score=0.889 total time=   1.0s\n",
      "[CV 3/5] END ..................C=5, gamma=0.001;, score=0.899 total time=   0.6s\n",
      "[CV 4/5] END ..................C=5, gamma=0.001;, score=0.880 total time=   0.6s\n",
      "[CV 5/5] END ..................C=5, gamma=0.001;, score=0.881 total time=   0.9s\n",
      "[CV 1/5] END ..................C=5, gamma=0.005;, score=0.900 total time=   0.9s\n",
      "[CV 2/5] END ..................C=5, gamma=0.005;, score=0.889 total time=   1.0s\n",
      "[CV 3/5] END ..................C=5, gamma=0.005;, score=0.899 total time=   0.6s\n",
      "[CV 4/5] END ..................C=5, gamma=0.005;, score=0.880 total time=   0.6s\n",
      "[CV 5/5] END ..................C=5, gamma=0.005;, score=0.881 total time=   0.9s\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.900 total time=   1.5s\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.888 total time=   1.4s\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.900 total time=   0.8s\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.878 total time=   1.1s\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.883 total time=   1.5s\n",
      "[CV 1/5] END ................C=10, gamma=0.0005;, score=0.900 total time=   1.5s\n",
      "[CV 2/5] END ................C=10, gamma=0.0005;, score=0.888 total time=   1.5s\n",
      "[CV 3/5] END ................C=10, gamma=0.0005;, score=0.900 total time=   0.8s\n",
      "[CV 4/5] END ................C=10, gamma=0.0005;, score=0.878 total time=   1.1s\n",
      "[CV 5/5] END ................C=10, gamma=0.0005;, score=0.883 total time=   1.6s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.900 total time=   1.6s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.888 total time=   1.5s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.900 total time=   0.8s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.878 total time=   1.1s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.883 total time=   1.6s\n",
      "[CV 1/5] END .................C=10, gamma=0.005;, score=0.900 total time=   1.4s\n",
      "[CV 2/5] END .................C=10, gamma=0.005;, score=0.888 total time=   1.4s\n",
      "[CV 3/5] END .................C=10, gamma=0.005;, score=0.900 total time=   0.8s\n",
      "[CV 4/5] END .................C=10, gamma=0.005;, score=0.878 total time=   1.1s\n",
      "[CV 5/5] END .................C=10, gamma=0.005;, score=0.883 total time=   1.6s\n",
      "[CV 1/5] END ................C=50, gamma=0.0001;, score=0.896 total time=   3.7s\n",
      "[CV 2/5] END ................C=50, gamma=0.0001;, score=0.888 total time=   4.4s\n",
      "[CV 3/5] END ................C=50, gamma=0.0001;, score=0.897 total time=   3.2s\n",
      "[CV 4/5] END ................C=50, gamma=0.0001;, score=0.879 total time=   2.9s\n",
      "[CV 5/5] END ................C=50, gamma=0.0001;, score=0.886 total time=   4.1s\n",
      "[CV 1/5] END ................C=50, gamma=0.0005;, score=0.896 total time=   3.6s\n",
      "[CV 2/5] END ................C=50, gamma=0.0005;, score=0.888 total time=   4.3s\n",
      "[CV 3/5] END ................C=50, gamma=0.0005;, score=0.897 total time=   3.2s\n",
      "[CV 4/5] END ................C=50, gamma=0.0005;, score=0.879 total time=   3.0s\n",
      "[CV 5/5] END ................C=50, gamma=0.0005;, score=0.886 total time=   4.1s\n",
      "[CV 1/5] END .................C=50, gamma=0.001;, score=0.896 total time=   3.7s\n",
      "[CV 2/5] END .................C=50, gamma=0.001;, score=0.888 total time=   4.4s\n",
      "[CV 3/5] END .................C=50, gamma=0.001;, score=0.897 total time=   3.2s\n",
      "[CV 4/5] END .................C=50, gamma=0.001;, score=0.879 total time=   3.0s\n",
      "[CV 5/5] END .................C=50, gamma=0.001;, score=0.886 total time=   4.1s\n",
      "[CV 1/5] END .................C=50, gamma=0.005;, score=0.896 total time=   3.7s\n",
      "[CV 2/5] END .................C=50, gamma=0.005;, score=0.888 total time=   4.4s\n",
      "[CV 3/5] END .................C=50, gamma=0.005;, score=0.897 total time=   3.2s\n",
      "[CV 4/5] END .................C=50, gamma=0.005;, score=0.879 total time=   2.9s\n",
      "[CV 5/5] END .................C=50, gamma=0.005;, score=0.886 total time=   4.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10, 50],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model with GridSearchCV\n",
    "\n",
    "grid_svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.0001}\n",
      "0.889754146078781\n"
     ]
    }
   ],
   "source": [
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931909212283045"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8878718535469108"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.81      0.71      0.76       411\n",
      "     CONFIRMED       0.78      0.84      0.81       484\n",
      "FALSE POSITIVE       0.98      1.00      0.99       853\n",
      "\n",
      "      accuracy                           0.89      1748\n",
      "     macro avg       0.86      0.85      0.85      1748\n",
      "  weighted avg       0.89      0.89      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "\n",
    "predict= grid_svm.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Support_Vector_Machine.sav']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'Support_Vector_Machine.sav'\n",
    "joblib.dump(svm_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try RandomForest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.9033180778032036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_model = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf_model.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf_model.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10679104936463797, 'FALSE POSITIVE'),\n",
       " (0.10068058509160106, 'CONFIRMED'),\n",
       " (0.06670616099726455, 'FALSE POSITIVE'),\n",
       " (0.054520791716888145, 'CONFIRMED'),\n",
       " (0.05075046523405153, 'CONFIRMED'),\n",
       " (0.03522330240457256, 'CONFIRMED'),\n",
       " (0.034557922024233065, 'CONFIRMED'),\n",
       " (0.03405206295089999, 'CONFIRMED'),\n",
       " (0.03333319066491026, 'CONFIRMED'),\n",
       " (0.0321063802158135, 'CANDIDATE'),\n",
       " (0.028716592286395965, 'FALSE POSITIVE'),\n",
       " (0.02754693150170348, 'CONFIRMED'),\n",
       " (0.023107310940822166, 'CONFIRMED'),\n",
       " (0.023079017388109958, 'CONFIRMED'),\n",
       " (0.02240992025410495, 'FALSE POSITIVE'),\n",
       " (0.022019006163826894, 'FALSE POSITIVE'),\n",
       " (0.021731907002698624, 'CONFIRMED'),\n",
       " (0.019306733642876977, 'CONFIRMED'),\n",
       " (0.019161134838190118, 'CONFIRMED'),\n",
       " (0.0191159064915393, 'FALSE POSITIVE'),\n",
       " (0.01727917195540506, 'CONFIRMED'),\n",
       " (0.016089951611169013, 'FALSE POSITIVE'),\n",
       " (0.015364649700427216, 'FALSE POSITIVE'),\n",
       " (0.013645986049839371, 'CONFIRMED'),\n",
       " (0.013300711229246434, 'FALSE POSITIVE'),\n",
       " (0.01295139028647225, 'CONFIRMED'),\n",
       " (0.012713025050977062, 'CONFIRMED'),\n",
       " (0.01173751092547861, 'FALSE POSITIVE'),\n",
       " (0.01149418108590088, 'CONFIRMED'),\n",
       " (0.011167917530753092, 'CONFIRMED'),\n",
       " (0.011085171896982517, 'FALSE POSITIVE'),\n",
       " (0.010971753661767246, 'FALSE POSITIVE'),\n",
       " (0.010393832985446563, 'CONFIRMED'),\n",
       " (0.01026390059489113, 'CONFIRMED'),\n",
       " (0.00962819143694259, 'CONFIRMED'),\n",
       " (0.008790370843451637, 'CONFIRMED'),\n",
       " (0.008727596304000055, 'CONFIRMED'),\n",
       " (0.008582855640481998, 'FALSE POSITIVE'),\n",
       " (0.008243489027179609, 'CONFIRMED'),\n",
       " (0.0026519710080465855, 'CONFIRMED')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clf_model.feature_importances_, y), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators': [250, 300, 350],\n",
    "              'max_depth': [125, 150, 175]}\n",
    "grid_clf = GridSearchCV(clf_model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ...max_depth=125, n_estimators=250;, score=0.901 total time=   2.6s\n",
      "[CV 2/5] END ...max_depth=125, n_estimators=250;, score=0.902 total time=   2.5s\n",
      "[CV 3/5] END ...max_depth=125, n_estimators=250;, score=0.883 total time=   2.6s\n",
      "[CV 4/5] END ...max_depth=125, n_estimators=250;, score=0.889 total time=   2.6s\n",
      "[CV 5/5] END ...max_depth=125, n_estimators=250;, score=0.883 total time=   2.6s\n",
      "[CV 1/5] END ...max_depth=125, n_estimators=300;, score=0.904 total time=   3.2s\n",
      "[CV 2/5] END ...max_depth=125, n_estimators=300;, score=0.904 total time=   3.2s\n",
      "[CV 3/5] END ...max_depth=125, n_estimators=300;, score=0.886 total time=   3.2s\n",
      "[CV 4/5] END ...max_depth=125, n_estimators=300;, score=0.885 total time=   3.0s\n",
      "[CV 5/5] END ...max_depth=125, n_estimators=300;, score=0.884 total time=   3.2s\n",
      "[CV 1/5] END ...max_depth=125, n_estimators=350;, score=0.903 total time=   3.8s\n",
      "[CV 2/5] END ...max_depth=125, n_estimators=350;, score=0.903 total time=   3.7s\n",
      "[CV 3/5] END ...max_depth=125, n_estimators=350;, score=0.884 total time=   3.7s\n",
      "[CV 4/5] END ...max_depth=125, n_estimators=350;, score=0.884 total time=   3.7s\n",
      "[CV 5/5] END ...max_depth=125, n_estimators=350;, score=0.882 total time=   3.7s\n",
      "[CV 1/5] END ...max_depth=150, n_estimators=250;, score=0.901 total time=   2.6s\n",
      "[CV 2/5] END ...max_depth=150, n_estimators=250;, score=0.902 total time=   2.5s\n",
      "[CV 3/5] END ...max_depth=150, n_estimators=250;, score=0.883 total time=   2.7s\n",
      "[CV 4/5] END ...max_depth=150, n_estimators=250;, score=0.889 total time=   2.5s\n",
      "[CV 5/5] END ...max_depth=150, n_estimators=250;, score=0.883 total time=   2.6s\n",
      "[CV 1/5] END ...max_depth=150, n_estimators=300;, score=0.904 total time=   3.2s\n",
      "[CV 2/5] END ...max_depth=150, n_estimators=300;, score=0.904 total time=   3.1s\n",
      "[CV 3/5] END ...max_depth=150, n_estimators=300;, score=0.886 total time=   3.1s\n",
      "[CV 4/5] END ...max_depth=150, n_estimators=300;, score=0.885 total time=   3.1s\n",
      "[CV 5/5] END ...max_depth=150, n_estimators=300;, score=0.884 total time=   3.1s\n",
      "[CV 1/5] END ...max_depth=150, n_estimators=350;, score=0.903 total time=   3.7s\n",
      "[CV 2/5] END ...max_depth=150, n_estimators=350;, score=0.903 total time=   3.6s\n",
      "[CV 3/5] END ...max_depth=150, n_estimators=350;, score=0.884 total time=   3.7s\n",
      "[CV 4/5] END ...max_depth=150, n_estimators=350;, score=0.884 total time=   3.6s\n",
      "[CV 5/5] END ...max_depth=150, n_estimators=350;, score=0.882 total time=   3.6s\n",
      "[CV 1/5] END ...max_depth=175, n_estimators=250;, score=0.901 total time=   2.7s\n",
      "[CV 2/5] END ...max_depth=175, n_estimators=250;, score=0.902 total time=   2.5s\n",
      "[CV 3/5] END ...max_depth=175, n_estimators=250;, score=0.883 total time=   2.6s\n",
      "[CV 4/5] END ...max_depth=175, n_estimators=250;, score=0.889 total time=   2.6s\n",
      "[CV 5/5] END ...max_depth=175, n_estimators=250;, score=0.883 total time=   2.5s\n",
      "[CV 1/5] END ...max_depth=175, n_estimators=300;, score=0.904 total time=   3.2s\n",
      "[CV 2/5] END ...max_depth=175, n_estimators=300;, score=0.904 total time=   3.2s\n",
      "[CV 3/5] END ...max_depth=175, n_estimators=300;, score=0.886 total time=   3.1s\n",
      "[CV 4/5] END ...max_depth=175, n_estimators=300;, score=0.885 total time=   3.1s\n",
      "[CV 5/5] END ...max_depth=175, n_estimators=300;, score=0.884 total time=   3.1s\n",
      "[CV 1/5] END ...max_depth=175, n_estimators=350;, score=0.903 total time=   3.7s\n",
      "[CV 2/5] END ...max_depth=175, n_estimators=350;, score=0.903 total time=   3.6s\n",
      "[CV 3/5] END ...max_depth=175, n_estimators=350;, score=0.884 total time=   3.7s\n",
      "[CV 4/5] END ...max_depth=175, n_estimators=350;, score=0.884 total time=   3.6s\n",
      "[CV 5/5] END ...max_depth=175, n_estimators=350;, score=0.882 total time=   3.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_estimators=500, random_state=1),\n",
       "             param_grid={'max_depth': [125, 150, 175],\n",
       "                         'n_estimators': [250, 300, 350]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 125, 'n_estimators': 300}\n",
      "0.8924249921772098\n"
     ]
    }
   ],
   "source": [
    "print(grid_clf.best_params_)\n",
    "print(grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902745995423341"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = grid_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.84      0.76      0.80       411\n",
      "     CONFIRMED       0.84      0.86      0.85       484\n",
      "FALSE POSITIVE       0.97      1.00      0.98       853\n",
      "\n",
      "      accuracy                           0.90      1748\n",
      "     macro avg       0.88      0.87      0.88      1748\n",
      "  weighted avg       0.90      0.90      0.90      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForest Classifier.sav']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'RandomForest Classifier.sav'\n",
    "joblib.dump(clf_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next try KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.804\n",
      "k: 3, Train/Test Score: 0.910/0.831\n",
      "k: 5, Train/Test Score: 0.889/0.832\n",
      "k: 7, Train/Test Score: 0.880/0.830\n",
      "k: 9, Train/Test Score: 0.874/0.830\n",
      "k: 11, Train/Test Score: 0.869/0.831\n",
      "k: 13, Train/Test Score: 0.865/0.826\n",
      "k: 15, Train/Test Score: 0.861/0.824\n",
      "k: 17, Train/Test Score: 0.860/0.824\n",
      "k: 19, Train/Test Score: 0.856/0.830\n",
      "k: 21, Train/Test Score: 0.856/0.834\n",
      "k: 23, Train/Test Score: 0.854/0.831\n",
      "k: 25, Train/Test Score: 0.848/0.832\n",
      "k: 27, Train/Test Score: 0.844/0.832\n",
      "k: 29, Train/Test Score: 0.845/0.824\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=27 Test Acc: 0.640\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=27)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=27 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=17 Test Acc: 0.634\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=19)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=17 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNN Classifier.sav']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'KNN Classifier.sav'\n",
    "joblib.dump(knn, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
